{
 "cells": [
  {
   "metadata": {
    "id": "8a77807f92f26ee"
   },
   "cell_type": "markdown",
   "source": [
    "# Title\n",
    "\n",
    "Project website: https://docs.google.com/document/d/1GkK28wOyjTPZEZuOumKPU0z1NzVT_9sxETjPOcLPVYo/edit?tab=t.0#heading=h.qifoo7co6qtd\n",
    "\n",
    "Professor website: https://malchiodi.di.unimi.it/teaching/AMD-DSE/2024-25/en"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "cell_type": "code",
   "source": [
    "#!git clone https://github.com/chiesastefano/massiveData\n",
    "import os\n",
    "#os.chdir(\"massiveData\")"
   ],
   "metadata": {
    "id": "RIRey329LtTM",
    "outputId": "2207f3a7-cfa0-4c8f-b472-cc45e86e139b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "RIRey329LtTM",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "4b98cbd80fe8cd48",
    "outputId": "68ee82e0-cb3e-4360-96cf-9bd1790a6156",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Install required packages from the requirement.txt file if not already installed\n",
    "!pip install -r requirements.txt"
   ],
   "id": "4b98cbd80fe8cd48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9edc57113f58ee11",
    "outputId": "3285511f-74f2-4f03-cf72-7b4d3b2d08f5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from key import key_secret\n",
    "\n",
    "# Set Your own Kaggle credentials\n",
    "os.environ['KAGGLE_USERNAME'] = \"ilchurch\"\n",
    "os.environ['KAGGLE_KEY'] = key_secret\n",
    "\n",
    "# Ensure kaggle is installed\n",
    "try:\n",
    "    import kaggle\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\"])\n",
    "    import kaggle\n",
    "\n",
    "# Import and authenticate using KaggleApi\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Check if the dataset file already exists\n",
    "if not os.path.exists('data/Books_rating.csv'):\n",
    "    api.dataset_download_files('mohamedbakhet/amazon-books-reviews', path='data', unzip=True)\n",
    "else:\n",
    "    print(\"Dataset already exists.\")"
   ],
   "id": "9edc57113f58ee11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "faa012f3baac4263",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset with spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"JaccardSimilarity\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "books_rating = spark.read.csv(\"data/Books_rating.csv\", header=True, inferSchema=True)"
   ],
   "id": "faa012f3baac4263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6f55fd13c5c4a70c",
    "outputId": "3c508b2b-d250-4219-c3e9-f326ab2d4a76",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the first few rows of the books_rating dataset\n",
    "books_rating.show(5)"
   ],
   "id": "6f55fd13c5c4a70c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "32f883874724060"
   },
   "cell_type": "markdown",
   "source": [
    "# Create a subsample of the dataset for performance reasons\n",
    "I will use a sample of the dataset as a test case. My local and Google Collab computers are not powerful enough to handle the full dataset. I will use *sample* as a parameter can it can be changed to the desired sample size."
   ],
   "id": "32f883874724060"
  },
  {
   "metadata": {
    "id": "53024733b148bdb4",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sample = 0.01 # 1% of the dataset"
   ],
   "id": "53024733b148bdb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "c1caef794a13d7d1",
    "outputId": "f023d7a0-8e9e-4d53-f08c-f8d51caba63c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "books_rating_sample = books_rating.sample(fraction=sample, seed=42)\n",
    "books_rating_sample.show(5)\n",
    "sample_size = books_rating_sample.count()"
   ],
   "id": "c1caef794a13d7d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sample_size"
   ],
   "metadata": {
    "id": "nP9yHAcUa9C0",
    "outputId": "3055cf29-fb69-4ded-bba2-08f86020bfcc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "nP9yHAcUa9C0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "dcb6e82c7d972535"
   },
   "cell_type": "markdown",
   "source": [
    "# Checking for null values in the 'review/text' column\n",
    "Since we are using text data, we need to check for null values in the 'review/text' column in order to take a decision on how to handle them."
   ],
   "id": "dcb6e82c7d972535"
  },
  {
   "metadata": {
    "id": "dcf56755a2c3a6d5",
    "outputId": "be15c681-d94e-44a6-80d4-3fa65bd08610",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for null values in the 'review/text' column\n",
    "null_rows_df = books_rating.filter(\n",
    "    books_rating['review/text'].isNull() | (books_rating['review/text'].rlike('^\\\\s*$'))\n",
    ")\n",
    "\n",
    "null_rows_df.show(30)"
   ],
   "id": "dcf56755a2c3a6d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "13b84fb5ae57aa62"
   },
   "cell_type": "markdown",
   "source": [
    "Since the 'review/text' null values are more or less duplicates.\n",
    "\n",
    "They share the same columns, besides the identifiers and the Title. Although the Title is not the same, with a qualitative check we can see they are about the same book."
   ],
   "id": "13b84fb5ae57aa62"
  },
  {
   "metadata": {
    "id": "5885180066a66507",
    "outputId": "6244b02b-aadc-4a8d-b0ee-6ca6d85c1cfe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import col\n",
    "filtered_df = books_rating.filter(\n",
    "    col(\"Title\").contains(\"Lord of the Rings\")\n",
    ").select(\"Title\", \"review/text\").limit(100)\n",
    "\n",
    "# Show the result\n",
    "filtered_df.show(100, truncate=False)"
   ],
   "id": "5885180066a66507",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6dcd6513675d7e10"
   },
   "cell_type": "markdown",
   "source": [
    "There are many others Lord of The Rings reviews. I think we can't discard the NA values and it's better to keep them. We can use also the Title as similarity check."
   ],
   "id": "6dcd6513675d7e10"
  },
  {
   "metadata": {
    "id": "a2cdb61db5f854cf"
   },
   "cell_type": "markdown",
   "source": [],
   "id": "a2cdb61db5f854cf"
  },
  {
   "metadata": {
    "id": "45b44dde088bb228",
    "outputId": "126507d3-0ed9-4f4f-e874-23fcc5a4643a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for null values in the 'review/text' column\n",
    "null_rows_df_sample = books_rating_sample.filter(\n",
    "    books_rating_sample['review/text'].isNull() | (books_rating_sample['review/text'].rlike('^\\\\s*$'))\n",
    ")\n",
    "\n",
    "null_rows_df_sample.show(30)"
   ],
   "id": "45b44dde088bb228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "fbdccfaafc82187e"
   },
   "cell_type": "markdown",
   "source": [
    "The is a null value in the subsample"
   ],
   "id": "fbdccfaafc82187e"
  },
  {
   "metadata": {
    "id": "533cd4951d48f00d"
   },
   "cell_type": "markdown",
   "source": [
    "# Jaccard Similarity"
   ],
   "id": "533cd4951d48f00d"
  },
  {
   "metadata": {
    "id": "1072c0152b9ecab2"
   },
   "cell_type": "markdown",
   "source": [
    "## Tokenization\n",
    "Since the dataset is too big, I will use a subsample of the dataset to test the Jaccard Similarity approach, for test purposes. I will then try top scale it to the full dataset.\n",
    "In addition, I will use the MapReduce approach to parallelize the computation of the Jaccard Similarity."
   ],
   "id": "1072c0152b9ecab2"
  },
  {
   "metadata": {
    "id": "5885315f727b57eb",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType"
   ],
   "id": "5885315f727b57eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "c6be9ffd0f620cb9",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"review/text\", outputCol=\"reviews/tokens\", pattern=\"\\\\W\") # \\\\W is a regex pattern that matches any non-word character"
   ],
   "id": "c6be9ffd0f620cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "d1275a324da74d22"
   },
   "cell_type": "markdown",
   "source": [
    "It tokenizes the text into words. I am trying this approach because I believe it will be faster then some neural network based approach, since this use sparks. It will have some limitations, since it does not take in account of compound words, but I think it will be good for the first approach."
   ],
   "id": "d1275a324da74d22"
  },
  {
   "metadata": {
    "id": "1fca258eea1e93f1",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "stopwords_remover = StopWordsRemover(inputCol=\"reviews/tokens\", outputCol=\"tokens/nostopwords\")"
   ],
   "id": "1fca258eea1e93f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "87c07acc08025c2c"
   },
   "cell_type": "markdown",
   "source": [
    "StopWordsRemover() uses a predefined list of stop words in English. It removes common words that do not carry much meaning, such as \"the\", \"is\", \"in\", etc. This is important, since the Jaccard Similarity is based on the number of common words between two texts. If we don't remove the stop words, the Jaccard Similarity will be biased by the number of stop words in the texts, which are not relevant for the meaning of the texts."
   ],
   "id": "87c07acc08025c2c"
  },
  {
   "metadata": {
    "id": "4707a6f993b28803",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_numbers(tokens):\n",
    "    return [token for token in tokens if not token.isdigit()]"
   ],
   "id": "4707a6f993b28803",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "593cab392a6b24df"
   },
   "cell_type": "markdown",
   "source": [
    "Numbers are often not relevant for the meaning of a review. In our dataset, the score is stored in a separated column, so we can remove the numbers from the text."
   ],
   "id": "593cab392a6b24df"
  },
  {
   "metadata": {
    "id": "5a62598dcf6f25a2",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "remove_numbers_udf = udf(remove_numbers, ArrayType(StringType())) # Specify the return type as ArrayType(StringType), meaning an array/list of strings"
   ],
   "id": "5a62598dcf6f25a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "c55d3aa47c162dab"
   },
   "cell_type": "markdown",
   "source": [
    "Sparks does not work as a Python object, so we need UDF (user defined function) to use it in the pipeline."
   ],
   "id": "c55d3aa47c162dab"
  },
  {
   "metadata": {
    "id": "ddaa3e8ad4c3282",
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_books_rating_sample = tokenizer.transform(books_rating_sample) # Apply the tokenizer to the dataset\n",
    "tokenized_reviews_nostopwords_sample = stopwords_remover.transform(tokenized_books_rating_sample) # Remove the stop words from the tokenized dataset\n",
    "tokenized_rw_nsw_nn_sample = tokenized_reviews_nostopwords_sample.withColumn(\"tokens/nostopwords/nonumbers\", remove_numbers_udf(col(\"tokens/nostopwords\"))) # Remove the numbers from the dataset"
   ],
   "id": "ddaa3e8ad4c3282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "337bce825f5607c6",
    "outputId": "1a1795dd-d1cb-4543-ae59-e9bc495d58bd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "books_rating_sample.show(10)\n",
    "tokenized_rw_nsw_nn_sample.show(10, truncate=True)"
   ],
   "id": "337bce825f5607c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "df_safe = tokenized_rw_nsw_nn_sample \\\n",
    "    .filter(col(\"review/text\").isNotNull())\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    inputCol=\"tokens/nostopwords/nonumbers\",\n",
    "    outputCol=\"features\",\n",
    "    vocabSize=5000,\n",
    "    minDF=10\n",
    ")\n",
    "\n",
    "model = cv.fit(df_safe)\n",
    "vocab = model.vocabulary\n"
   ],
   "metadata": {
    "id": "q-0wCeXlSEcl",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "q-0wCeXlSEcl",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We need CountVectorizer() to create a vocabulary of the tokens. It will create a vocabulary of the most frequent tokens in the dataset. The vocabSize parameter is the maximum size of the vocabulary. The minDF parameter is the minimum number of documents that must contain a token for it to be included in the vocabulary. This is important, since we want to remove rare tokens that are not relevant for the meaning of the texts.",
   "id": "190a4241125a616a"
  },
  {
   "cell_type": "code",
   "source": [
    "top30 = model.vocabulary[:30]\n",
    "print(\"Top 30 tokens (approx. by frequency):\")\n",
    "for i, token in enumerate(top30, start=1):\n",
    "    print(f\"{i:2d}. {token}\")"
   ],
   "metadata": {
    "id": "BGbA8ZIMXG4B",
    "outputId": "e30483f3-8fb9-47f2-eacf-b13652dd6fb9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "BGbA8ZIMXG4B",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This method approximates the top 30 words in the vocaboulary. However, it doesn't show the frequency, since CountVectorizer() only approximates the real frequency of the top words. I want to find them."
   ],
   "metadata": {
    "id": "juJWNAF1ZBWJ"
   },
   "id": "juJWNAF1ZBWJ"
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "exploded = df_safe.select(explode(col(\"tokens/nostopwords/nonumbers\")).alias(\"token\")) \n",
    "\n",
    "# Filter to only the top-20 tokens\n",
    "topK_set = set(model.vocabulary[:20])  # top 20 from vocab\n",
    "filtered = exploded.filter(col(\"token\").isin(topK_set))\n",
    "\n",
    "exact_counts = (filtered.groupBy(\"token\").count().orderBy(col(\"count\").desc()))\n",
    "exact_counts.show(truncate=False)"
   ],
   "metadata": {
    "id": "nm1ZhXjZZRlD",
    "outputId": "9cf66d32-e21d-48f6-98d9-11872c5ea142",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "nm1ZhXjZZRlD",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "1OgbY8RXbRWt"
   },
   "id": "1OgbY8RXbRWt"
  },
  {
   "cell_type": "code",
   "source": [
    "threshold = 0.20 * sample_size # You can change the percentage of the sample size to set the threshold\n",
    "print(threshold)"
   ],
   "metadata": {
    "id": "re8lQKJXcrg8",
    "outputId": "7282b545-233f-44d9-abcb-de1b49048050",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "re8lQKJXcrg8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "I defined a function that only keeps the tokens which are not in the custom_stopwords list"
   ],
   "metadata": {
    "id": "UUpgocTXcsgH"
   },
   "id": "UUpgocTXcsgH"
  },
  {
   "cell_type": "code",
   "source": [
    "high_freq_tokens = (exact_counts.filter(col(\"count\") > threshold).select(\"token\")\n",
    "      .rdd.flatMap(lambda x: x)\n",
    "      .collect()\n",
    ")"
   ],
   "metadata": {
    "id": "QE1X2OXzcAw8",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "QE1X2OXzcAw8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "high_freq_tokens"
   ],
   "metadata": {
    "id": "X8UmpBKreiMU",
    "outputId": "1f68fbdb-5881-49ec-de46-3e99a76b25b0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "X8UmpBKreiMU",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_custom_stopwords(tokens):\n",
    "    return [t for t in tokens if t not in high_freq_tokens] \n",
    "\n",
    "remove_udf = udf(remove_custom_stopwords, ArrayType(StringType()))\n",
    "\n",
    "tokenized_sample_2 = tokenized_rw_nsw_nn_sample.withColumn(\n",
    "    \"tokens_clean\",\n",
    "    remove_udf(col(\"tokens/nostopwords/nonumbers\"))\n",
    ")"
   ],
   "metadata": {
    "id": "T3qIjrVVeBYW",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "T3qIjrVVeBYW",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Filter out the tokens that are in the stopwords list.",
   "id": "ab42a9ed01829d81"
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import size\n",
    "df_safe = tokenized_sample_2.filter(col(\"review/text\").isNotNull())\n",
    "\n",
    "empty_tokens_count = df_safe.filter(\n",
    "    (size(col(\"tokens_clean\")) == 0) |\n",
    "    (col(\"tokens_clean\").isNull())\n",
    ").count()\n",
    "\n",
    "print(f\"Number of records with empty tokens_clean: {empty_tokens_count}\")"
   ],
   "metadata": {
    "id": "BEZdegzGAuwi",
    "outputId": "2db7e2e3-acbc-493a-d2ca-4e43805d604e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "BEZdegzGAuwi",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sparks does not work well with empty lists, so we need to filter out the rows with empty lists. We can do this by using the size() and isNull() function to check if the list is empty or null",
   "id": "cf80486c40f76607"
  },
  {
   "cell_type": "code",
   "source": [
    "cv = CountVectorizer(\n",
    "    inputCol=\"tokens_clean\",\n",
    "    outputCol=\"features\",\n",
    "    vocabSize=5000,\n",
    "    minDF=10\n",
    ")\n",
    "\n",
    "model2 = cv.fit(df_safe)\n",
    "vocab2 = model2.vocabulary\n"
   ],
   "metadata": {
    "id": "ljhJMlsIfHxo",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "ljhJMlsIfHxo",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "top30 = model2.vocabulary[:30]\n",
    "print(\"Top 30 tokens (approx. by frequency):\")\n",
    "for i, token in enumerate(top30, start=1):\n",
    "    print(f\"{i:2d}. {token}\")"
   ],
   "metadata": {
    "id": "Cm9d9gHdfNSO",
    "outputId": "adb4ef99-6f8d-4f38-eb2b-616c040f8afa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "Cm9d9gHdfNSO",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We verified that the top words are now different, since the previous one got correctly filtered out",
   "id": "8d7408d0c2daf484"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Local Sensitive Hashing\n",
    "\n",
    "Since the project must be scalable, we can't compute the Jaccard similarity on the whole dataset. Instead, we can use Local Sensitive Hashing (LSH) to compute the Jaccard similarity in a distributed way. LSH is a method that hashes similar input items into the same \"buckets\" with high probability. It is used to find similar items in large datasets efficiently.\n",
    "You can find more informations about it in the book \"Mining of Massive Datasets\" by Anand Rajaraman and Jeffrey, free to download at http://infolab.stanford.edu/~ullman/mmds/book.pdf (Section 3.3.4 and  3.4.1).\n"
   ],
   "metadata": {
    "id": "Nq5P2ClqBkx2"
   },
   "id": "Nq5P2ClqBkx2"
  },
  {
   "cell_type": "code",
   "source": "sim_threshold = 0.6 # You can change it at your will",
   "metadata": {
    "id": "yoUalgkRVszv",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "yoUalgkRVszv",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_safe.show(10)"
   ],
   "metadata": {
    "id": "QhnF29EQgG16",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "QhnF29EQgG16",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Filter out rows where tokens_clean is null or empty\n",
    "df_nonempty = df_safe.filter((df_safe.tokens_clean.isNotNull()) & (size(df_safe.tokens_clean) > 0))"
   ],
   "metadata": {
    "id": "P3IkwXAvlcL8",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "P3IkwXAvlcL8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import HashingTF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"tokens_clean\", outputCol=\"features\", numFeatures= 8192) \n",
    "df_featurized = hashingTF.transform(df_nonempty) "
   ],
   "metadata": {
    "id": "R1iHs6Y1kdg0",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "R1iHs6Y1kdg0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.HashingTF.html it suggested to use 2^n as numFeatures, where n is the number of bits. I used 8192, since is the first power of 2 which is greater than 5000, the size of the vocabulary. This is important, since we want to avoid collisions in the hashing process.",
   "id": "cc0735a386357a7d"
  },
  {
   "cell_type": "code",
   "source": [
    "df_featurized.show(10)"
   ],
   "metadata": {
    "id": "TKGhN2YilO9q",
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "TKGhN2YilO9q",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import MinHashLSH\n",
    "\n",
    "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=10) # You can change the number of hash tables at your will\n",
    "model = mh.fit(df_featurized)"
   ],
   "metadata": {
    "id": "TRzFLoP0lFn4",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T08:26:56.603740Z"
    }
   },
   "id": "TRzFLoP0lFn4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The column \"hashes\" contains the hashed values of the features. The numHashTables parameter is the number of hash tables to use. The more hash tables we use, the more accurate the results will be, but it will also take more time to compute. I used 2 hash tables, since it is a good trade-off between accuracy and performance.",
   "id": "3bffd3126a58ed6c"
  },
  {
   "cell_type": "code",
   "source": [
    "similar_pairs = model.approxSimilarityJoin(\n",
    "    df_featurized, df_featurized, threshold=sim_threshold, distCol=\"JaccardDistance\"\n",
    ").filter(\"datasetA.Id < datasetB.Id\")  # to avoid duplicate/reverse pairs\n",
    "\n",
    "similar_pairs = similar_pairs.orderBy(\"JaccardDistance\", ascending=False)"
   ],
   "metadata": {
    "id": "fJUpUMsilH1S",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T08:26:56.619699Z"
    }
   },
   "id": "fJUpUMsilH1S",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T08:26:56.745364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similar_pairs.select(\n",
    "    \"datasetA.Title\", \"datasetB.Title\", \"datasetA.Id\", \"datasetB.Id\", \"datasetA.review/text\", \"datasetB.review/text\", \"JaccardDistance\"\n",
    ").show(2, truncate=False)"
   ],
   "id": "3110027afba10e50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T08:30:38.750606Z"
    }
   },
   "cell_type": "code",
   "source": "first_pair = similar_pairs.first()",
   "id": "4326b4c0783ba5ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Accessing the review text of the first similar pair\n",
    "review_a = first_pair['datasetA']['review/text']\n",
    "review_b = first_pair['datasetB']['review/text']\n",
    "\n",
    "# Printing the reviews\n",
    "print(\"Review 1 (datasetA):\")\n",
    "print(review_a)\n",
    "print(\"\\nReview 2 (datasetB):\")\n",
    "print(review_b)"
   ],
   "id": "7ef2cdbacafc1707",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It looks like it works, since the two review share the words \"very happy with purchase\"",
   "id": "e511d481818123ad"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the text/review of the first similar pair   \n",
    "similar_pairs.select(\"datasetA.review/text\", \"datasetB.review/text\").show(2, truncate=False)"
   ],
   "id": "7467d693d5c37c13",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
