{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Title\n",
    "\n",
    "Project website: https://docs.google.com/document/d/1GkK28wOyjTPZEZuOumKPU0z1NzVT_9sxETjPOcLPVYo/edit?tab=t.0#heading=h.qifoo7co6qtd\n",
    "\n",
    "Professor website: https://malchiodi.di.unimi.it/teaching/AMD-DSE/2024-25/en"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Install required packages from the requirement.txt file if not already installed\n",
    "!pip install -r requirements.txt"
   ],
   "id": "4b98cbd80fe8cd48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5e02fb13e986f4bc"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set environment variables for Kaggle API\n",
    "os.environ['KAGGLE_USERNAME'] = \"ilchurch\"\n",
    "os.environ['KAGGLE_KEY'] = \"5449548f4b6c8556c8f48f4a31b4ea6e\"\n",
    "\n",
    "# Ensure kaggle is installed\n",
    "try:\n",
    "    import kaggle\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\"])\n",
    "    import kaggle\n",
    "\n",
    "# Import and authenticate using KaggleApi\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Download and unzip the dataset\n",
    "api.dataset_download_files('mohamedbakhet/amazon-books-reviews', path='data', unzip=True)"
   ],
   "id": "9edc57113f58ee11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:29:30.693401Z",
     "start_time": "2025-04-30T10:29:30.690282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# amazon_books_data\n",
    "# The dataset contains the following files:\n",
    "# - books_data.csv: \n",
    "# - Books_rating.csv:"
   ],
   "id": "aca7278898d62aff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:29:32.154553Z",
     "start_time": "2025-04-30T10:29:32.110502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset with spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JaccardSimilarity\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "books_rating = spark.read.csv(\"data/Books_rating.csv\", header=True, inferSchema=True)"
   ],
   "id": "faa012f3baac4263",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark.conf'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load the dataset with spark\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n\u001B[0;32m      3\u001B[0m spark \u001B[38;5;241m=\u001B[39m SparkSession\u001B[38;5;241m.\u001B[39mbuilder \\\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;241m.\u001B[39mappName(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJaccardSimilarity\u001B[39m\u001B[38;5;124m\"\u001B[39m) \\\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;241m.\u001B[39mmaster(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocal[*]\u001B[39m\u001B[38;5;124m\"\u001B[39m) \\\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;241m.\u001B[39mgetOrCreate()\n\u001B[0;32m      7\u001B[0m books_rating \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mcsv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/Books_rating.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, inferSchema\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pyspark\\__init__.py:58\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m filterwarnings\n\u001B[0;32m     54\u001B[0m filterwarnings(\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistutils Version classes are deprecated. Use packaging.version instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     56\u001B[0m )\n\u001B[1;32m---> 58\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkConf\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrdd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RDD, RDDBarrier\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfiles\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkFiles\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pyspark.conf'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T10:28:53.993305Z",
     "start_time": "2025-04-30T10:28:53.993305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the first few rows of the books_rating dataset\n",
    "books_rating.show(5)"
   ],
   "id": "6f55fd13c5c4a70c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create a subsample of the dataset for performance reasons\n",
    "I will use a sample of the dataset as a test case. My local and Google Collab computers are not powerful enough to handle the full dataset. I will use *sample* as a parameter can it can be changed to the desired sample size."
   ],
   "id": "32f883874724060"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sample = 0.01 # 1% of the dataset",
   "id": "53024733b148bdb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "books_rating_sample = books_rating.sample(fraction=sample, seed=42)\n",
    "books_rating_sample.show(5)\n",
    "books_rating_sample.count()"
   ],
   "id": "c1caef794a13d7d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Checking for null values in the 'review/text' column\n",
    "Since we are using text data, we need to check for null values in the 'review/text' column in order to take a decision on how to handle them."
   ],
   "id": "dcb6e82c7d972535"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for null values in the 'review/text' column\n",
    "null_rows_df = books_rating.filter(\n",
    "    books_rating['review/text'].isNull() | (books_rating['review/text'].rlike('^\\\\s*$'))\n",
    ")\n",
    "\n",
    "null_rows_df.show(30)"
   ],
   "id": "dcf56755a2c3a6d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Since the 'review/text' null values are more or less duplicates. \n",
    "\n",
    "They share the same columns, besides the identifiers and the Title. Although the Title is not the same, with a qualitative check we can see they are about the same book."
   ],
   "id": "13b84fb5ae57aa62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import col\n",
    "filtered_df = books_rating.filter(\n",
    "    col(\"Title\").contains(\"Lord of the Rings\")\n",
    ").select(\"Title\", \"review/text\").limit(100)\n",
    "\n",
    "# Show the result\n",
    "filtered_df.show(100, truncate=False)"
   ],
   "id": "5885180066a66507",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are many others Lord of The Rings reviews. I think we can't discard the NA values and it's better to keep them. We can use also the Title as similarity check.",
   "id": "6dcd6513675d7e10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a2cdb61db5f854cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for null values in the 'review/text' column\n",
    "null_rows_df_sample = books_rating_sample.filter(\n",
    "    books_rating_sample['review/text'].isNull() | (books_rating_sample['review/text'].rlike('^\\\\s*$'))\n",
    ")\n",
    "\n",
    "null_rows_df_sample.show(30)"
   ],
   "id": "45b44dde088bb228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The is a null value in the subsample",
   "id": "fbdccfaafc82187e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Working with the subsample",
   "id": "533cd4951d48f00d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Jaccard Similarity Approach\n",
    "Since the dataset is too big, I will use a subsample of the dataset to test the Jaccard Similarity approach, for test purposes. I will then try top scale it to the full dataset.\n",
    "In addition, I will use the MapReduce approach to parallelize the computation of the Jaccard Similarity."
   ],
   "id": "1072c0152b9ecab2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import ArrayType, StringType"
   ],
   "id": "5885315f727b57eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer = RegexTokenizer(inputCol=\"review/text\", outputCol=\"reviews/tokens\", pattern=\"\\\\W\") # \\\\W is a regex pattern that matches any non-word character",
   "id": "c6be9ffd0f620cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It tokenizes the text into words. I am trying this approach because I believe it will be faster then some neural network based approach, since this use sparks. It will have some limitations, since it does not take in account of compound words, but I think it will be good for the first approach.",
   "id": "d1275a324da74d22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "stopwords_remover = StopWordsRemover(inputCol=\"reviews/tokens\", outputCol=\"tokens/nostopwords\")",
   "id": "1fca258eea1e93f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "StopWordsRemover() uses a predefined list of stop words in English. It removes common words that do not carry much meaning, such as \"the\", \"is\", \"in\", etc. This is important, since the Jaccard Similarity is based on the number of common words between two texts. If we don't remove the stop words, the Jaccard Similarity will be biased by the number of stop words in the texts, which are not relevant for the meaning of the texts.",
   "id": "87c07acc08025c2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def remove_numbers(tokens):\n",
    "    return [token for token in tokens if not token.isdigit()]"
   ],
   "id": "4707a6f993b28803",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Numbers are often not relevant for the meaning of a review. In our dataset, the score is stored in a separated column, so we can remove the numbers from the text.",
   "id": "593cab392a6b24df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "remove_numbers_udf = udf(remove_numbers, ArrayType(StringType())) # Specify the return type as ArrayType(StringType), meaning an array/list of strings",
   "id": "5a62598dcf6f25a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sparks does not work as a Python object, so we need UDF (user defined function) to use it in the pipeline.",
   "id": "c55d3aa47c162dab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenized_books_rating_sample = tokenizer.transform(books_rating_sample) # Apply the tokenizer to the dataset\n",
    "tokenized_reviews_nostopwords_sample = stopwords_remover.transform(tokenized_books_rating_sample) # Remove the stop words from the tokenized dataset\n",
    "tokenized_rw_nsw_nn_sample = tokenized_reviews_nostopwords_sample.withColumn(\"tokens/nostopwords/nonumbers\", remove_numbers_udf(col(\"tokens/nostopwords\"))) # Remove the numbers from the dataset"
   ],
   "id": "ddaa3e8ad4c3282",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenized_rw_nsw_nn_sample.show(10)",
   "id": "337bce825f5607c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
